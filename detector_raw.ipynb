{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db05d197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from xgboost import plot_tree\n",
    "import graphviz\n",
    "from xgboost import to_graphviz\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29f2535",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eec9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_count = train_data['Label'].value_counts()\n",
    "\n",
    "print(particle_count)\n",
    "\n",
    "statistical_count = train_data.describe()\n",
    "\n",
    "# print(statistical_count)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c09ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "particle_types = train_data['Label'].unique()\n",
    "\n",
    "for particle in particle_types:\n",
    "    \n",
    "    subset = train_data[train_data['Label'] == particle]\n",
    "    \n",
    "    sns.histplot(data=subset, x='TrackP', log_scale=True, element=\"step\", common_norm=False, fill=True, alpha=0.2, label=particle)\n",
    "\n",
    "plt.title('Momentum Distribution for Each Particle Type', fontsize=16)\n",
    "plt.xlabel('Track Momentum (TrackP) - Log Scale', fontsize=12)\n",
    "plt.ylabel('Number of Particles', fontsize=12)\n",
    "plt.legend(title='Particle Type')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8cc259",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Replacing -999.0 with 0\")\n",
    "train_data.replace(-999.0, 0, inplace=True)\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d2fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data['Label']\n",
    "X = train_data.drop('Label', axis=1)\n",
    "\n",
    "print(\"X and y created successfully\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=73)\n",
    "\n",
    "print(\"Done Splitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daabeea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68366972",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_enc = LabelEncoder()\n",
    "y_train_encoded = lab_enc.fit_transform(y_train)\n",
    "y_test_encoded = lab_enc.transform(y_test)\n",
    "print(\"Label mapping:\")\n",
    "for i, class_name in enumerate(lab_enc.classes_):\n",
    "    print(f\"'{class_name}' -> {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b8b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_model = RandomForestClassifier(n_estimators=100, random_state=73, n_jobs=-1)\n",
    "# rf_model.fit(X_train, y_train)\n",
    "# print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d626078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = rf_model.predict(X_test)\n",
    "# print(\"Predictions complete.\")\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"\\nModel Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f58950",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(n_estimators=100, random_state=73, use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "xgb_model.fit(X_train, y_train_encoded)\n",
    "print(\"Training Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a3d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "accuracy_xgb = accuracy_score(y_test_encoded, y_pred_xgb)\n",
    "print(f\"\\nXGBoost Model Accuracy: {accuracy_xgb * 100:.2f}%\")\n",
    "print(classification_report(y_test_encoded, y_pred_xgb, target_names=lab_enc.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb28c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "X_train_scaled = scalar.fit_transform(X_train)\n",
    "X_test_scaled = scalar.fit_transform(X_test)\n",
    "print(\"Data scaling complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80990e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_model = keras.Sequential([\n",
    "#   keras.layers.Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "#   keras.layers.Dense(64, activation='relu'),\n",
    "#   keras.layers.Dense(6, activation='softmax')\n",
    "# ])\n",
    "# nn_model.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='sparse_categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "# print(\"Model Summary\")\n",
    "\n",
    "\n",
    "# nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd9b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importances = xgb_model.feature_importances_\n",
    "feature_names = X.columns # Assumes 'X' is your DataFrame of features\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df.head(15), palette='viridis')\n",
    "plt.title('Top 15 Most Important Features for the Champion XGBoost Model', fontsize=16)\n",
    "plt.xlabel('Importance Score (Higher is More Important)', fontsize=12)\n",
    "plt.ylabel('Feature Name', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bb5a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n--- Generating Visual #2: Confusion Matrix ---\")\n",
    "\n",
    "cm = confusion_matrix(y_test_encoded, y_pred_xgb, labels=xgb_model.classes_)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lab_enc.classes_)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "disp.plot(ax=ax, cmap='Blues', xticks_rotation='vertical')\n",
    "plt.title('Confusion Matrix for the Champion XGBoost Model', fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6796eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probabilities = xgb_model.predict_proba(X_test)\n",
    "\n",
    "print(f\"Probabilities generated. The shape of the output is: {pred_probabilities.shape}\")\n",
    "\n",
    "print(\"\\nProbabilities for the first 5 particles:\")\n",
    "print(np.round(pred_probabilities[:5], 3))\n",
    "\n",
    "confidence_scores = np.max(pred_probabilities, axis=1)\n",
    "\n",
    "print(\"\\nConfidence scores for the first 5 particles:\")\n",
    "print(np.round(confidence_scores[:5], 3))\n",
    "\n",
    "anomaly_df = pd.DataFrame({\n",
    "    'Original_ID': X_test.index,\n",
    "    'Confidence': confidence_scores\n",
    "})\n",
    "\n",
    "most_anomalous_particles = anomaly_df.sort_values(by='Confidence', ascending=True)\n",
    "\n",
    "print(most_anomalous_particles.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c2598",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_anomaly_id = most_anomalous_particles.iloc[0]['Original_ID']\n",
    "\n",
    "\n",
    "anomaly_index_in_preds = X_test.index.get_loc(top_anomaly_id)\n",
    "anomaly_probs = pred_probabilities[anomaly_index_in_preds]\n",
    "\n",
    "prob_report = pd.Series(anomaly_probs, index=lab_enc.classes_)\n",
    "\n",
    "print(\"\\nModel's Probability Breakdown for this Particle:\")\n",
    "print(prob_report.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29228a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_anomaly_ids = most_anomalous_particles.head(10)['Original_ID']\n",
    "\n",
    "top_10_anomaly_features = X_test.loc[top_10_anomaly_ids]\n",
    "\n",
    "print(top_10_anomaly_features.describe())\n",
    "\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Original_ID': X_test.index,\n",
    "    'Prediction': y_pred_xgb, \n",
    "    'Confidence': confidence_scores\n",
    "})\n",
    "\n",
    "confident_muons = results_df[\n",
    "    (results_df['Prediction'] == 3) & (results_df['Confidence'] > 0.999)\n",
    "].head(10)\n",
    "\n",
    "confident_muon_features = X_test.loc[confident_muons['Original_ID']]\n",
    "\n",
    "print(confident_muon_features.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525e5d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9261e921",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Visual 1: Muon Identification with MuonFlag ---\")\n",
    "\n",
    "# Let's use a sample of the full X_train and y_train_encoded for plotting\n",
    "# Otherwise, plotting all 840k points might be slow or clunky\n",
    "plot_df = pd.DataFrame(X_train_scaled, columns=X.columns) # Use scaled data for consistency\n",
    "plot_df['Particle_Label'] = lab_enc.inverse_transform(y_train_encoded)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='MuonFlag', hue='Particle_Label', data=plot_df, palette='tab10')\n",
    "plt.title('Distribution of MuonFlag for Different Particles', fontsize=14)\n",
    "plt.xlabel('Muon Flag (0 = No, 1 = Yes)', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.legend(title='Particle Type')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e56831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "particle_subset = plot_df[plot_df['Particle_Label'].isin(['Electron', 'Proton', 'Pion', 'Kaon'])]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x='HcalE', y='EcalE', hue='Particle_Label', data=particle_subset.sample(n=10000, random_state=42),\n",
    "                alpha=0.6, s=20, palette='viridis') \n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log') \n",
    "plt.xlim(1e-3, 1e2)\n",
    "plt.ylim(1e-3, 1e2)\n",
    "\n",
    "plt.title('Calorimeter Energy Deposit (EcalE vs HcalE)', fontsize=14)\n",
    "plt.xlabel('Hadronic Calorimeter Energy (HcalE)', fontsize=12)\n",
    "plt.ylabel('Electromagnetic Calorimeter Energy (EcalE)', fontsize=12)\n",
    "plt.legend(title='Particle Type')\n",
    "plt.grid(True, which=\"both\", ls=\"--\", c='0.7')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b038c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kp_subset = plot_df[plot_df['Particle_Label'].isin(['Kaon', 'Proton'])].sample(n=10000, random_state=42)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x='RICH_DLLbeKaon', y='RICH_DLLbeProton', hue='Particle_Label', data=kp_subset,\n",
    "                alpha=0.6, s=20, palette={'Kaon': 'green', 'Proton': 'blue'})\n",
    "\n",
    "plt.xlim(-5, 5) \n",
    "plt.ylim(-5, 5)\n",
    "\n",
    "plt.axhline(0, color='grey', linestyle='--', linewidth=0.8) \n",
    "plt.axvline(0, color='grey', linestyle='--', linewidth=0.8)\n",
    "\n",
    "plt.title('(Kaons vs. Protons)', fontsize=14)\n",
    "plt.xlabel('RICH_DLLbeKaon ', fontsize=12)\n",
    "plt.ylabel('RICH_DLLbeProton ', fontsize=12)\n",
    "plt.legend(title='Particle Type')\n",
    "plt.grid(True, which=\"both\", ls=\"--\", c='0.7')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af6696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_features = importance_df['Feature'].head(3).tolist()\n",
    "print(f\"Plotting the 3 most important features the model used: {top_3_features}\")\n",
    "\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X.columns, index=X_test.index)\n",
    "\n",
    "anomaly_ids = most_anomalous_particles.head(100)['Original_ID']\n",
    "anomaly_points = X_test_scaled_df.loc[anomaly_ids]\n",
    "\n",
    "normal_ids = X_test_scaled_df.index.difference(anomaly_ids)\n",
    "normal_sample_ids = np.random.choice(normal_ids, size=5000, replace=False)\n",
    "normal_points = X_test_scaled_df.loc[normal_sample_ids]\n",
    "\n",
    "print(\"Generating the final 3D anomaly plot... This might take a moment.\")\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(normal_points[top_3_features[0]],\n",
    "           normal_points[top_3_features[1]],\n",
    "           normal_points[top_3_features[2]],\n",
    "           c='blue',\n",
    "           alpha=0.3,  \n",
    "           s=5,       \n",
    "           label='Normal Particles (Sample)')\n",
    "\n",
    "ax.scatter(anomaly_points[top_3_features[0]],\n",
    "           anomaly_points[top_3_features[1]],\n",
    "           anomaly_points[top_3_features[2]],\n",
    "           c='red',\n",
    "           alpha=0.9, \n",
    "           s=30,       \n",
    "           label='Anomalies')\n",
    "\n",
    "ax.set_xlabel(top_3_features[0], fontsize=12)\n",
    "ax.set_ylabel(top_3_features[1], fontsize=12)\n",
    "ax.set_zlabel(top_3_features[2], fontsize=12)\n",
    "ax.set_title(' Anomalies in the Space', fontsize=16)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825832a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
